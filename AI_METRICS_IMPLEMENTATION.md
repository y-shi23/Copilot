# AI æ€§èƒ½æŒ‡æ ‡è®¡æ•°å®ç°æŒ‡å—

> æœ¬æ–‡æ¡£æä¾›åœ¨ Vue + TypeScript é¡¹ç›®ä¸­å®ç° AI æ€§èƒ½æŒ‡æ ‡è®¡æ•°çš„å®Œæ•´æŠ€æœ¯æ–¹æ¡ˆ

## ğŸ“‹ ç›®å½•

- [åŠŸèƒ½æ¦‚è¿°](#åŠŸèƒ½æ¦‚è¿°)
- [æŠ€æœ¯æ¶æ„](#æŠ€æœ¯æ¶æ„)
- [æ•°æ®ç»“æ„å®šä¹‰](#æ•°æ®ç»“æ„å®šä¹‰)
- [æ ¸å¿ƒå®ç°](#æ ¸å¿ƒå®ç°)
- [Vue é›†æˆ](#vue-é›†æˆ)
- [å®Œæ•´ä»£ç ç¤ºä¾‹](#å®Œæ•´ä»£ç ç¤ºä¾‹)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## åŠŸèƒ½æ¦‚è¿°

éœ€è¦å®ç°ä¸‰ä¸ªæ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡ï¼š

1. **é¦–å­—æ—¶å»¶ (Time to First Token, TTFT)**ï¼šä»å‘é€è¯·æ±‚åˆ°æ”¶åˆ°ç¬¬ä¸€ä¸ª token çš„æ—¶é—´
2. **æ¯ç§’ Tokens (Tokens Per Second, TPS)**ï¼štoken ç”Ÿæˆé€Ÿåº¦
3. **ä¸Šä¸‹è¡Œ Tokens**ï¼šè¾“å…¥(prompt) å’Œ è¾“å‡º(completion) çš„ token æ•°é‡

---

## æŠ€æœ¯æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Vue Component Layer                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ MessageList â”‚  â”‚ MetricsDisplay â”‚  â”‚ TokenCounter      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Metrics Service Layer                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  MetricsTracker - æ ¸å¿ƒè®¡æ•°é€»è¾‘                        â”‚   â”‚
â”‚  â”‚  - é¦–å­—æ—¶å»¶è¿½è¸ª                                       â”‚   â”‚
â”‚  â”‚  - Token ç´¯ç§¯è®¡æ•°                                    â”‚   â”‚
â”‚  â”‚  - æ€§èƒ½æŒ‡æ ‡è®¡ç®—                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI Stream Layer                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  StreamProcessor - æµå¼å“åº”å¤„ç†                       â”‚   â”‚
â”‚  â”‚  - SSE/WebSocket æ¶ˆæ¯è§£æ                            â”‚   â”‚
â”‚  â”‚  - Chunk åˆ†ç‰‡å¤„ç†                                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## æ•°æ®ç»“æ„å®šä¹‰

### 1. Metrics ç±»å‹å®šä¹‰

```typescript
// src/types/ai-metrics.ts

/**
 * AI æ¶ˆæ¯æ€§èƒ½æŒ‡æ ‡
 */
export interface AIMetrics {
  /** è¾“å‡º token æ•°é‡ */
  completion_tokens: number;

  /** è¾“å…¥ token æ•°é‡ */
  prompt_tokens: number;

  /** æ€» token æ•°é‡ */
  total_tokens: number;

  /** é¦–å­—æ—¶å»¶ï¼ˆæ¯«ç§’ï¼‰ */
  time_first_token_millsec?: number;

  /** æ€»å®Œæˆæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ */
  time_completion_millsec: number;

  /** æ€è€ƒæ—¶é—´ï¼ˆç”¨äºæ¨ç†æ¨¡å‹ï¼Œæ¯«ç§’ï¼‰ */
  time_thinking_millsec?: number;

  /** Token ç”Ÿæˆé€Ÿåº¦ï¼ˆtokens/ç§’ï¼‰ */
  token_speed?: number;
}

/**
 * è®¡æ•°å™¨çŠ¶æ€
 */
export interface MetricsTrackerState {
  /** è¯·æ±‚å¼€å§‹æ—¶é—´æˆ³ */
  request_start_timestamp: number;

  /** é¦–ä¸ª token æ—¶é—´æˆ³ */
  first_token_timestamp?: number;

  /** å®Œæˆæ—¶é—´æˆ³ */
  completion_timestamp?: number;

  /** æ˜¯å¦å·²æ”¶åˆ°é¦–ä¸ª token */
  has_first_token: boolean;

  /** å½“å‰ç´¯ç§¯çš„ token æ•° */
  accumulated_tokens: number;

  /** è¾“å…¥ token æ•°é‡ï¼ˆé¢„ä¼°æˆ–ä» API è·å–ï¼‰ */
  prompt_tokens: number;
}

/**
 * æµå¼å“åº” Chunk æ•°æ®ç»“æ„
 */
export interface StreamChunk {
  /** token å†…å®¹ */
  content?: string;

  /** Usage ä¿¡æ¯ï¼ˆéƒ¨åˆ† API æä¾›ï¼‰ */
  usage?: {
    completion_tokens?: number;
    prompt_tokens?: number;
    total_tokens?: number;
  };

  /** æ˜¯å¦ä¸ºæ€è€ƒå†…å®¹ï¼ˆæ¨ç†æ¨¡å‹ï¼‰ */
  is_thinking?: boolean;
}
```

---

## æ ¸å¿ƒå®ç°

### 2. MetricsTracker æ ¸å¿ƒç±»

````typescript
// src/services/ai/MetricsTracker.ts

import type { AIMetrics, MetricsTrackerState, StreamChunk } from '@/types/ai-metrics';

/**
 * AI æ€§èƒ½æŒ‡æ ‡è¿½è¸ªå™¨
 *
 * @example
 * ```ts
 * const tracker = new MetricsTracker();
 * tracker.start();
 * // ... streaming ...
 * tracker.accumulateChunk(chunk);
 * const metrics = tracker.finalize();
 * ```
 */
export class MetricsTracker {
  private state: MetricsTrackerState;

  constructor() {
    this.state = {
      request_start_timestamp: 0,
      first_token_timestamp: undefined,
      completion_timestamp: undefined,
      has_first_token: false,
      accumulated_tokens: 0,
      prompt_tokens: 0,
    };
  }

  /**
   * å¼€å§‹è¿½è¸ªï¼ˆå‘é€è¯·æ±‚å‰è°ƒç”¨ï¼‰
   */
  start(prompt_tokens?: number): void {
    this.state = {
      request_start_timestamp: this.getTimestamp(),
      first_token_timestamp: undefined,
      completion_timestamp: undefined,
      has_first_token: false,
      accumulated_tokens: 0,
      prompt_tokens: prompt_tokens || 0,
    };
  }

  /**
   * å¤„ç†æµå¼å“åº” chunk
   *
   * @param chunk - æµå¼å“åº”æ•°æ®å—
   */
  accumulateChunk(chunk: StreamChunk): void {
    // æ ‡è®°é¦–ä¸ª token æ—¶é—´
    if (!this.state.has_first_token && this.shouldCountAsToken(chunk)) {
      this.state.first_token_timestamp = this.getTimestamp();
      this.state.has_first_token = true;
    }

    // ç´¯ç§¯ token æ•°é‡
    if (chunk.usage?.completion_tokens !== undefined) {
      // API æä¾›äº†å‡†ç¡®çš„ token è®¡æ•°
      this.state.accumulated_tokens = chunk.usage.completion_tokens;
    } else if (chunk.content) {
      // éœ€è¦è‡ªå·±ä¼°ç®—ï¼šç®€å•æŒ‰å­—ç¬¦æ•°ä¼°ç®—ï¼ˆ1 token â‰ˆ 4 å­—ç¬¦ï¼‰
      // æ›´ç²¾ç¡®çš„æ–¹å¼è§ TokenEstimator
      this.state.accumulated_tokens += this.estimateTokens(chunk.content);
    }
  }

  /**
   * å®Œæˆè¿½è¸ªå¹¶è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
   *
   * @returns å®Œæ•´çš„æ€§èƒ½æŒ‡æ ‡
   */
  finalize(): AIMetrics {
    const completion_timestamp = this.getTimestamp();
    this.state.completion_timestamp = completion_timestamp;

    const time_completion_millsec = completion_timestamp - this.state.request_start_timestamp;

    const time_first_token_millsec = this.state.first_token_timestamp
      ? this.state.first_token_timestamp - this.state.request_start_timestamp
      : undefined;

    const token_speed =
      time_completion_millsec > 0
        ? this.state.accumulated_tokens / (time_completion_millsec / 1000)
        : 0;

    const total_tokens = this.state.prompt_tokens + this.state.accumulated_tokens;

    return {
      completion_tokens: this.state.accumulated_tokens,
      prompt_tokens: this.state.prompt_tokens,
      total_tokens,
      time_first_token_millsec,
      time_completion_millsec,
      token_speed,
    };
  }

  /**
   * åˆ¤æ–­ chunk æ˜¯å¦åº”è®¡ä¸º token
   */
  private shouldCountAsToken(chunk: StreamChunk): boolean {
    return Boolean(chunk.content && chunk.content.trim().length > 0 && !chunk.is_thinking);
  }

  /**
   * ç®€å• token ä¼°ç®—ï¼ˆ1 token â‰ˆ 4 å­—ç¬¦ï¼Œé’ˆå¯¹è‹±æ–‡ï¼‰
   *
   * @note æ›´ç²¾ç¡®çš„ä¼°ç®—éœ€è¦ä¸“é—¨çš„ tokenizer
   */
  private estimateTokens(text: string): number {
    // ç®€å•ä¼°ç®—ï¼šè‹±æ–‡çº¦ 4 å­—ç¬¦/tokenï¼Œä¸­æ–‡çº¦ 2 å­—ç¬¦/token
    const chineseChars = (text.match(/[\u4e00-\u9fa5]/g) || []).length;
    const otherChars = text.length - chineseChars;

    return Math.ceil(chineseChars / 2 + otherChars / 4);
  }

  /**
   * è·å–é«˜ç²¾åº¦æ—¶é—´æˆ³
   */
  private getTimestamp(): number {
    // æµè§ˆå™¨ç¯å¢ƒ
    if (typeof performance !== 'undefined' && performance.now) {
      return performance.now();
    }
    // Node.js ç¯å¢ƒæˆ–å…¶ä»–
    return Date.now();
  }

  /**
   * è·å–å½“å‰çŠ¶æ€ï¼ˆç”¨äºè°ƒè¯•ï¼‰
   */
  getState(): Readonly<MetricsTrackerState> {
    return { ...this.state };
  }
}
````

---

### 3. Token ä¼°ç®—å™¨ï¼ˆå¯é€‰ï¼Œç”¨äºæ›´ç²¾ç¡®çš„è¾“å…¥ token é¢„ä¼°ï¼‰

```typescript
// src/services/ai/TokenEstimator.ts

/**
 * Token ä¼°ç®—å™¨
 *
 * ç”¨äºåœ¨ API ä¸æä¾› usage ä¿¡æ¯æ—¶ï¼Œé¢„ä¼°è¾“å…¥ token æ•°é‡
 */
export class TokenEstimator {
  /**
   * ä¼°ç®—æ–‡æœ¬çš„ token æ•°é‡
   *
   * @param text - è¦ä¼°ç®—çš„æ–‡æœ¬
   * @returns é¢„ä¼°çš„ token æ•°é‡
   */
  static estimateTextTokens(text: string): number {
    if (!text) return 0;

    // ç®€å•ç­–ç•¥
    const chineseChars = (text.match(/[\u4e00-\u9fa5]/g) || []).length;
    const otherChars = text.length - chineseChars;

    return Math.ceil(chineseChars / 2 + otherChars / 4);
  }

  /**
   * ä¼°ç®—æ¶ˆæ¯åˆ—è¡¨çš„ token æ•°é‡
   *
   * @param messages - OpenAI æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
   * @returns é¢„ä¼°çš„æ€» token æ•°é‡
   */
  static estimateMessagesTokens(messages: Array<{ role: string; content: string }>): number {
    let total = 0;

    // æ¯æ¡æ¶ˆæ¯çš„å…ƒæ•°æ®å¼€é”€ï¼ˆrole ç­‰å­—æ®µï¼‰
    const metadataTokensPerMessage = 4;

    for (const message of messages) {
      total += metadataTokensPerMessage;
      total += this.estimateTextTokens(message.content);
    }

    // å›å¤æ¨¡æ¿çš„å¼€é”€
    total += 3;

    return total;
  }

  /**
   * ä¼°ç®—å›¾ç‰‡çš„ token æ•°é‡ï¼ˆç”¨äºè§†è§‰æ¨¡å‹ï¼‰
   *
   * @param file - å›¾ç‰‡æ–‡ä»¶
   * @returns é¢„ä¼°çš„ token æ•°é‡
   */
  static estimateImageTokens(file: File | { size: number }): number {
    // OpenAI çš„å›¾ç‰‡ token è®¡ç®—ï¼šæ¯ 100 å­—èŠ‚çº¦ 1 token
    // åŸºç¡€å¼€é”€ 85 tokens + å›¾ç‰‡å°ºå¯¸ tokens
    const baseTokens = 85;
    const sizeTokens = Math.ceil(file.size / 100);
    return baseTokens + sizeTokens;
  }
}
```

---

### 4. æµå¼è¯·æ±‚å¤„ç†å™¨

```typescript
// src/services/ai/StreamProcessor.ts

import type { AIMetrics } from '@/types/ai-metrics';
import { MetricsTracker } from './MetricsTracker';
import { TokenEstimator } from './TokenEstimator';

/**
 * æµå¼ AI è¯·æ±‚å¤„ç†å™¨
 *
 * æ•´åˆäº†æµå¼è¯·æ±‚å¤„ç†å’Œæ€§èƒ½æŒ‡æ ‡è¿½è¸ª
 */
export class StreamProcessor {
  private tracker: MetricsTracker;
  private abortController: AbortController | null = null;

  constructor() {
    this.tracker = new MetricsTracker();
  }

  /**
   * å‘é€æµå¼è¯·æ±‚
   *
   * @param endpoint - API ç«¯ç‚¹
   * @param messages - æ¶ˆæ¯åˆ—è¡¨
   * @param onChunk - æ¥æ”¶åˆ° chunk æ—¶çš„å›è°ƒ
   * @param onComplete - å®Œæˆæ—¶çš„å›è°ƒ
   * @param onError - é”™è¯¯å›è°ƒ
   */
  async streamChat(
    endpoint: string,
    messages: Array<{ role: string; content: string }>,
    onChunk: (chunk: string) => void,
    onComplete: (fullResponse: string, metrics: AIMetrics) => void,
    onError: (error: Error) => void,
  ): Promise<void> {
    try {
      // 1. é¢„ä¼°è¾“å…¥ tokens
      const prompt_tokens = TokenEstimator.estimateMessagesTokens(messages);

      // 2. å¼€å§‹è¿½è¸ª
      this.tracker.start(prompt_tokens);

      // 3. åˆ›å»ºè¯·æ±‚
      this.abortController = new AbortController();

      const response = await fetch(endpoint, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ messages, stream: true }),
        signal: this.abortController.signal,
      });

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      // 4. å¤„ç†æµå¼å“åº”
      const reader = response.body?.getReader();
      if (!reader) {
        throw new Error('No response body');
      }

      const decoder = new TextDecoder();
      let fullResponse = '';

      while (true) {
        const { done, value } = await reader.read();

        if (done) break;

        // è§£ç å¹¶è§£æ SSE æ ¼å¼
        const chunk = decoder.decode(value, { stream: true });
        const lines = chunk.split('\n').filter((line) => line.trim());

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = line.slice(6);

            // è·³è¿‡ [DONE] æ ‡è®°
            if (data === '[DONE]') continue;

            try {
              const parsed = JSON.parse(data);

              // æå–å†…å®¹
              const content = parsed.choices?.[0]?.delta?.content || '';

              // æå– usageï¼ˆéƒ¨åˆ† API åœ¨æœ€åè¿”å›ï¼‰
              const usage = parsed.usage;

              // æ›´æ–°è¿½è¸ªå™¨
              this.tracker.accumulateChunk({
                content,
                usage: usage
                  ? {
                      completion_tokens: usage.completion_tokens,
                      prompt_tokens: usage.prompt_tokens,
                      total_tokens: usage.total_tokens,
                    }
                  : undefined,
              });

              // å›è°ƒ
              if (content) {
                fullResponse += content;
                onChunk(content);
              }
            } catch (e) {
              console.error('Failed to parse SSE data:', e);
            }
          }
        }
      }

      // 5. å®Œæˆè¿½è¸ª
      const metrics = this.tracker.finalize();
      onComplete(fullResponse, metrics);
    } catch (error) {
      if (error instanceof Error && error.name === 'AbortError') {
        console.log('Stream aborted');
      } else {
        onError(error as Error);
      }
    } finally {
      this.abortController = null;
    }
  }

  /**
   * å–æ¶ˆå½“å‰è¯·æ±‚
   */
  abort(): void {
    this.abortController?.abort();
  }
}
```

---

## Vue é›†æˆ

### 5. Vue Composableï¼ˆæ¨èæ–¹å¼ï¼‰

````typescript
// src/composables/useAIMetrics.ts

import { ref, computed, type Ref } from 'vue';
import type { AIMetrics } from '@/types/ai-metrics';
import { MetricsTracker } from '@/services/ai/MetricsTracker';
import { TokenEstimator } from '@/services/ai/TokenEstimator';

/**
 * AI æ€§èƒ½æŒ‡æ ‡ Composable
 *
 * @example
 * ```ts
 * const { metrics, startTracking, accumulateChunk, finalizeTracking } = useAIMetrics();
 * ```
 */
export function useAIMetrics() {
  const tracker = new MetricsTracker();

  // å“åº”å¼çŠ¶æ€
  const metrics = ref<AIMetrics | null>(null);
  const isTracking = ref(false);

  /**
   * å¼€å§‹è¿½è¸ª
   */
  const startTracking = (messages: Array<{ role: string; content: string }>) => {
    const prompt_tokens = TokenEstimator.estimateMessagesTokens(messages);
    tracker.start(prompt_tokens);
    isTracking.value = true;
    metrics.value = null;
  };

  /**
   * ç´¯ç§¯ chunk
   */
  const accumulateChunk = (chunk: { content?: string; usage?: any }) => {
    if (isTracking.value) {
      tracker.accumulateChunk(chunk);
    }
  };

  /**
   * å®Œæˆè¿½è¸ª
   */
  const finalizeTracking = () => {
    if (isTracking.value) {
      metrics.value = tracker.finalize();
      isTracking.value = false;
    }
    return metrics.value;
  };

  /**
   * æ ¼å¼åŒ–æ˜¾ç¤º
   */
  const formattedMetrics = computed(() => {
    if (!metrics.value) return null;

    return {
      é¦–å­—æ—¶å»¶: metrics.value.time_first_token_millsec
        ? `${metrics.value.time_first_token_millsec.toFixed(0)} ms`
        : '-',

      æ¯ç§’Tokens: metrics.value.token_speed ? `${metrics.value.token_speed.toFixed(0)} tok/s` : '-',

      è¾“å…¥: `${metrics.value.prompt_tokens} tokens`,
      è¾“å‡º: `${metrics.value.completion_tokens} tokens`,
    };
  });

  return {
    metrics,
    isTracking,
    startTracking,
    accumulateChunk,
    finalizeTracking,
    formattedMetrics,
  };
}
````

---

### 6. Vue ç»„ä»¶ç¤ºä¾‹

```vue
<!-- src/components/ChatMessage.vue -->

<template>
  <div class="chat-message">
    <div class="message-header">
      <span class="role">{{ message.role }}</span>
      <span v-if="metrics" class="metrics">
        â†‘{{ metrics.prompt_tokens }} â†“{{ metrics.completion_tokens }}
      </span>
    </div>

    <div class="message-content">
      {{ message.content }}
    </div>

    <!-- æ€§èƒ½æŒ‡æ ‡æ‚¬æµ®æç¤º -->
    <el-popover v-if="metrics" placement="top" :width="200" trigger="hover">
      <template #reference>
        <div class="metrics-badge">
          <el-icon><InfoFilled /></el-icon>
        </div>
      </template>

      <div class="metrics-detail">
        <div class="metric-row">
          <span>é¦–å­—æ—¶å»¶:</span>
          <span>{{ formatFirstToken }}</span>
        </div>
        <div class="metric-row">
          <span>ç”Ÿæˆé€Ÿåº¦:</span>
          <span>{{ formatTokenSpeed }}</span>
        </div>
        <div class="metric-row">
          <span>æ€»è€—æ—¶:</span>
          <span>{{ formatTotalTime }}</span>
        </div>
        <div class="metric-row">
          <span>è¾“å…¥ Tokens:</span>
          <span>{{ metrics.prompt_tokens }}</span>
        </div>
        <div class="metric-row">
          <span>è¾“å‡º Tokens:</span>
          <span>{{ metrics.completion_tokens }}</span>
        </div>
      </div>
    </el-popover>
  </div>
</template>

<script setup lang="ts">
import { computed } from 'vue';
import { InfoFilled } from '@element-plus/icons-vue';
import type { AIMetrics } from '@/types/ai-metrics';

interface Props {
  message: {
    role: 'user' | 'assistant';
    content: string;
  };
  metrics?: AIMetrics | null;
}

const props = defineProps<Props>();

const formatFirstToken = computed(() => {
  if (!props.metrics?.time_first_token_millsec) return '-';
  return `${props.metrics.time_first_token_millsec.toFixed(0)} ms`;
});

const formatTokenSpeed = computed(() => {
  if (!props.metrics?.token_speed) return '-';
  return `${props.metrics.token_speed.toFixed(0)} tok/s`;
});

const formatTotalTime = computed(() => {
  if (!props.metrics?.time_completion_millsec) return '-';
  return `${(props.metrics.time_completion_millsec / 1000).toFixed(2)} s`;
});
</script>

<style scoped>
.chat-message {
  position: relative;
  padding: 12px;
  margin-bottom: 8px;
  border-radius: 8px;
  background: #f5f5f5;
}

.message-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 8px;
  font-size: 12px;
  color: #666;
}

.metrics {
  font-family: monospace;
}

.metrics-badge {
  position: absolute;
  top: 8px;
  right: 8px;
  cursor: pointer;
  opacity: 0.5;
  transition: opacity 0.2s;
}

.metrics-badge:hover {
  opacity: 1;
}

.metrics-detail {
  font-size: 12px;
}

.metric-row {
  display: flex;
  justify-content: space-between;
  padding: 4px 0;
  border-bottom: 1px solid #eee;
}

.metric-row:last-child {
  border-bottom: none;
}
</style>
```

---

### 7. å®Œæ•´ä½¿ç”¨ç¤ºä¾‹

```vue
<!-- src/views/ChatView.vue -->

<template>
  <div class="chat-view">
    <div class="messages">
      <ChatMessage v-for="msg in messages" :key="msg.id" :message="msg" :metrics="msg.metrics" />
    </div>

    <div class="input-area">
      <el-input
        v-model="userInput"
        type="textarea"
        placeholder="è¾“å…¥æ¶ˆæ¯..."
        @keydown.enter.ctrl="sendMessage"
      />
      <el-button type="primary" :loading="isLoading" @click="sendMessage"> å‘é€ </el-button>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref } from 'vue';
import { useAIMetrics } from '@/composables/useAIMetrics';
import { StreamProcessor } from '@/services/ai/StreamProcessor';
import type { AIMetrics } from '@/types/ai-metrics';

interface Message {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  metrics?: AIMetrics;
}

const messages = ref<Message[]>([]);
const userInput = ref('');
const isLoading = ref(false);

// AI æŒ‡æ ‡è¿½è¸ª
const { startTracking, accumulateChunk, finalizeTracking } = useAIMetrics();

// æµå¼å¤„ç†å™¨
let streamProcessor: StreamProcessor | null = null;

const sendMessage = async () => {
  if (!userInput.value.trim() || isLoading.value) return;

  // 1. æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
  const userMessage: Message = {
    id: Date.now().toString(),
    role: 'user',
    content: userInput.value,
  };
  messages.value.push(userMessage);

  const input = userInput.value;
  userInput.value = '';
  isLoading.value = true;

  // 2. å‡†å¤‡åŠ©æ‰‹æ¶ˆæ¯å ä½
  const assistantMessage: Message = {
    id: (Date.now() + 1).toString(),
    role: 'assistant',
    content: '',
  };
  messages.value.push(assistantMessage);

  // 3. å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
  const requestMessages = messages.value
    .filter((m) => m.role === 'user' || m.role === 'assistant')
    .map((m) => ({ role: m.role, content: m.content }));

  // 4. å¼€å§‹è¿½è¸ª
  startTracking(requestMessages);

  // 5. å‘é€æµå¼è¯·æ±‚
  streamProcessor = new StreamProcessor();

  await streamProcessor.streamChat(
    '/api/chat', // ä½ çš„ API ç«¯ç‚¹
    requestMessages,
    // onChunk: æ¥æ”¶åˆ°å†…å®¹æ—¶æ›´æ–° UI
    (chunk: string) => {
      assistantMessage.content += chunk;
      accumulateChunk({ content: chunk });
    },
    // onComplete: å®Œæˆæ—¶ä¿å­˜æŒ‡æ ‡
    (fullResponse: string, metrics: AIMetrics) => {
      assistantMessage.metrics = finalizeTracking();
      isLoading.value = false;
    },
    // onError: é”™è¯¯å¤„ç†
    (error: Error) => {
      assistantMessage.content = `Error: ${error.message}`;
      isLoading.value = false;
    },
  );
};
</script>
```

---

## å®Œæ•´ä»£ç ç¤ºä¾‹

### æ–‡ä»¶ç»“æ„

```
src/
â”œâ”€â”€ types/
â”‚   â””â”€â”€ ai-metrics.ts          # ç±»å‹å®šä¹‰
â”œâ”€â”€ services/
â”‚   â””â”€â”€ ai/
â”‚       â”œâ”€â”€ MetricsTracker.ts  # æ ¸å¿ƒè¿½è¸ªå™¨
â”‚       â”œâ”€â”€ TokenEstimator.ts  # Token ä¼°ç®—å™¨
â”‚       â””â”€â”€ StreamProcessor.ts # æµå¼å¤„ç†å™¨
â”œâ”€â”€ composables/
â”‚   â””â”€â”€ useAIMetrics.ts       # Vue Composable
â””â”€â”€ components/
    â””â”€â”€ ChatMessage.vue        # æ¶ˆæ¯ç»„ä»¶
```

---

## æœ€ä½³å®è·µ

### âœ… æ¨èåšæ³•

1. **ä½¿ç”¨ performance.now()**

   ```typescript
   // âœ… é«˜ç²¾åº¦
   const timestamp = performance.now();

   // âŒ ä½ç²¾åº¦
   const timestamp = Date.now();
   ```

2. **åœ¨è¯·æ±‚å‰ç«‹å³å¼€å§‹è¿½è¸ª**

   ```typescript
   // âœ… å‡†ç¡®
   tracker.start();
   await fetch(endpoint, ...);

   // âŒ ä¸å‡†ç¡®
   tracker.start();
   await someAsyncOperation();
   await fetch(endpoint, ...);
   ```

3. **å¤„ç† API æä¾›çš„ usage ä¿¡æ¯**

   ```typescript
   // âœ… ä¼˜å…ˆä½¿ç”¨ API æä¾›çš„æ•°æ®
   if (chunk.usage?.completion_tokens) {
     this.accumulated_tokens = chunk.usage.completion_tokens;
   } else {
     // å›é€€åˆ°ä¼°ç®—
     this.accumulated_tokens += this.estimateTokens(chunk.content);
   }
   ```

4. **ä½¿ç”¨ TypeScript ç±»å‹**

   ```typescript
   // âœ… ç±»å‹å®‰å…¨
   const metrics: AIMetrics = tracker.finalize();
   ```

5. **åœ¨ç»„ä»¶é”€æ¯æ—¶æ¸…ç†**

   ```typescript
   import { onUnmounted } from 'vue';

   onUnmounted(() => {
     streamProcessor?.abort();
   });
   ```

---

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•å¤„ç†æ¨ç†æ¨¡å‹ï¼ˆå¦‚ o1ï¼‰çš„"æ€è€ƒ"æ—¶é—´ï¼Ÿ

```typescript
// æ‰©å±• AIMetrics ç±»å‹
interface ExtendedAIMetrics extends AIMetrics {
  time_thinking_millsec?: number;
}

// åœ¨ accumulateChunk ä¸­
if (chunk.is_thinking) {
  // æ€è€ƒå†…å®¹ä¸è®¡å…¥é¦–å­—æ—¶å»¶
  if (!this.state.thinking_start_timestamp) {
    this.state.thinking_start_timestamp = this.getTimestamp();
  }
} else if (!this.state.has_first_token) {
  // ç¬¬ä¸€ä¸ªéæ€è€ƒå†…å®¹æ‰ä½œä¸ºé¦–å­—
  this.state.first_token_timestamp = this.getTimestamp();
  this.state.has_first_token = true;
}
```

---

### Q2: å¦‚ä½•æé«˜ token ä¼°ç®—ç²¾åº¦ï¼Ÿ

**æ–¹æ³•ä¸€ï¼šä½¿ç”¨ä¸“é—¨çš„ tokenizer**

```typescript
// å®‰è£…ï¼šnpm install gpt-tokenizer
import { encode } from 'gpt-tokenizer';

export class TokenEstimator {
  static estimateTextTokens(text: string): number {
    return encode(text).length;
  }
}
```

**æ–¹æ³•äºŒï¼šAPI é¢„ä¼°ç®—ï¼ˆæ¨èï¼‰**

```typescript
// å‘é€ä¸€ä¸ªæ— æµå¼çš„è¯·æ±‚è·å–å‡†ç¡®çš„ usage
async preEstimateTokens(messages: Message[]) {
  const response = await fetch(endpoint, {
    method: 'POST',
    body: JSON.stringify({ messages, max_tokens: 1 }),
  });
  return response.usage.prompt_tokens;
}
```

---

### Q3: å¦‚ä½•å¤„ç† SSE ä¹‹å¤–çš„åè®®ï¼ˆWebSocketï¼‰ï¼Ÿ

```typescript
export class WebSocketStreamProcessor {
  private ws: WebSocket | null = null;
  private tracker: MetricsTracker;

  async streamChat(
    url: string,
    messages: Message[],
    onChunk: (chunk: string) => void,
    onComplete: (metrics: AIMetrics) => void,
  ) {
    this.tracker = new MetricsTracker();
    this.tracker.start();

    this.ws = new WebSocket(url);

    this.ws.onopen = () => {
      this.ws?.send(JSON.stringify({ messages, stream: true }));
    };

    this.ws.onmessage = (event) => {
      const data = JSON.parse(event.data);

      // WebSocket åè®®çš„ chunk è§£æ
      const content = data.content;
      const usage = data.usage;

      this.tracker.accumulateChunk({ content, usage });

      if (content) {
        onChunk(content);
      }

      if (data.done) {
        const metrics = this.tracker.finalize();
        onComplete(metrics);
        this.ws?.close();
      }
    };
  }
}
```

---

### Q4: å¤šè½®å¯¹è¯ä¸­å¦‚ä½•è®¡ç®—ä¸Šä¸‹æ–‡ tokensï¼Ÿ

```typescript
// å‡è®¾ messages æ˜¯å®Œæ•´çš„å†å²æ¶ˆæ¯
const calculateContextTokens = (messages: Message[]) => {
  let total = 0;

  // éå†æ‰€æœ‰å†å²æ¶ˆæ¯
  for (const msg of messages) {
    total += TokenEstimator.estimateTextTokens(msg.content);

    // æ¯æ¡æ¶ˆæ¯çš„å…ƒæ•°æ®å¼€é”€
    total += 4; // role å­—æ®µç­‰
  }

  // ç³»ç»Ÿæç¤ºè¯é¢å¤–å¼€é”€
  total += 10;

  return total;
};
```

---

### Q5: å¦‚ä½•åœ¨ Pinia Store ä¸­é›†æˆï¼Ÿ

```typescript
// src/stores/aiMetrics.ts
import { defineStore } from 'pinia';
import type { AIMetrics } from '@/types/ai-metrics';
import { MetricsTracker } from '@/services/ai/MetricsTracker';

export const useAIMetricsStore = defineStore('aiMetrics', {
  state: () => ({
    currentTracker: null as MetricsTracker | null,
    history: [] as Array<{ messageId: string; metrics: AIMetrics }>,
  }),

  actions: {
    startTracking() {
      this.currentTracker = new MetricsTracker();
      this.currentTracker.start();
    },

    accumulateChunk(chunk: any) {
      this.currentTracker?.accumulateChunk(chunk);
    },

    finalizeTracking(messageId: string) {
      if (!this.currentTracker) return null;

      const metrics = this.currentTracker.finalize();
      this.history.push({ messageId, metrics });
      this.currentTracker = null;

      return metrics;
    },

    getMetricsById(messageId: string) {
      return this.history.find((h) => h.messageId === messageId)?.metrics;
    },
  },
});
```

---

## æ€»ç»“

æœ¬æ–‡æ¡£æä¾›äº†åœ¨ Vue + TypeScript é¡¹ç›®ä¸­å®ç° AI æ€§èƒ½æŒ‡æ ‡è®¡æ•°çš„å®Œæ•´æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼š

1. âœ… **é¦–å­—æ—¶å»¶** - ä½¿ç”¨ `performance.now()` ç²¾ç¡®è®¡æ—¶
2. âœ… **æ¯ç§’ Tokens** - å®Œæˆåè®¡ç®— `tokens / time`
3. âœ… **ä¸Šä¸‹è¡Œ Tokens** - æµå¼ç´¯ç§¯ + API usage ä¿¡æ¯

æ ¸å¿ƒä¼˜åŠ¿ï¼š

- **é«˜ç²¾åº¦è®¡æ—¶** - æ¯«ç§’çº§å‡†ç¡®åº¦
- **æµå¼å®æ—¶æ›´æ–°** - ä¸é˜»å¡ UI
- **ç±»å‹å®‰å…¨** - å®Œæ•´ TypeScript æ”¯æŒ
- **æ˜“äºé›†æˆ** - Composable è®¾è®¡
- **å¯æ‰©å±•** - æ”¯æŒæ¨ç†æ¨¡å‹ã€å¤šè½®å¯¹è¯ç­‰

æŒ‰æœ¬æ–‡æ¡£å®ç°ï¼Œå³å¯åœ¨ä½ çš„ Vue é¡¹ç›®ä¸­è·å¾—ä¸å‚è€ƒé¡¹ç›®ç›¸åŒçš„æ€§èƒ½æŒ‡æ ‡è¿½è¸ªèƒ½åŠ›ï¼
